\documentclass[paper.tex]{subfiles}
\begin{document}

\section{Improving Accuracy with  \casio}
\label{sec:synthesis}

\todo{Given the subtlety floating point error, producing the
  minimal-error program for a given real number formula is intractable
  \footnote{\todo{\cite{}} shows this task is NP-hard}.}

\casio improves program accuracy via a heuristic search
  over programs that compute the same value in different ways.
Unlike conventional compilers, \casio is free
  to translate while changing the semantics of the translated program.

\subsection{Equivalent input and output}

\casio guides this search process by sampling many input points
  and evaluating candidate programs on these points.
Since \casio's search is guided by sampled points,
  there is a danger that \casio might overfit,
  resulting in a final program that is very accurate on the sampled points
  but not on general floating point numbers.
To prevent overfitting, \casio is required to return
  programs which, interpreted as real number formulas,
  are equivalent to the original.
This restricts the set of programs \casio can produce,
  and largely eliminates overfitting,
  since the programs \casio can produce must be valid implementations
  of the same formula as the input.

Formally, consider two semantics for programs:
  a real-number semantics,
  where each constant and variable is a real number
  and each operator is a function from reals to reals;
  and a floating-point semantics,
  where each constant and variable is truncated to a floating-point number
  and where each function is replaced by its floating-point version.
\casio's transformations must preserve the real-number semantics of programs,
  but may change the floating-point semantics.
Some important transformations
  can preserve the real-number semantics of a program,
  except at isolated points.
For example, the transformation $x + y \leadsto (x^2 - y^2)/(x - y)$
  does not preserve the real-number semantics when $x = y$.
This class of transformations is useful for improving the accuracy of programs,
  so instead of requiring that the input and output program
  are equivalent in the real semantics,
  we only require that they are equivalent where both are defined.
We call such programs \emph{real-equivalent}.

Since \casio must not change the real-number semantics of programs
  (except by changing where the program is defined),
  it is natural to structure \casio
  as applying a sequence of rewrite rules,
  each of which preserve real equivalence.
These rules are specified as input and output patterns;
  for example, the transformation above is a rule,
  with $x$ and $y$ matching arbitrary subexpressions.
\casio contains \nRewrites rules,
  including those for
  the commutativity, associativity, distributivity, and identity
  of basic arithmetic operators;
  fraction arithmetic;
  laws of squares, square roots, exponents, and logarithms;
  and some basic facts of trigonometry.

Each of these rules is a basic fact of algebra;
  it incorporates no understanding of numerical methods.
In preparing the rules,
  care was taken to ensure that rules
  do not change the real-number semantics of programs.
This was usually easy, but required some care
  to avoid false ``identities'' such as $\sqrt{x^2} = x$
  (this identity being false for negative $x$).

\subsection{The main loop}

The simplest approach to using this database of rewrites
  is a hill-climbing brute force search,
  where one applies rewrite rules at random,
  keeping the transformations where error behavior is improved.
Unfortunately, this method is not effective:
  too much time is spent on rewrites
  that have no effect on program accuracy,
  and sequences of rewrites that would improve accuracy
  are often not found, since intermediary steps do not neccessarily improve error.
Often, multiple rewrites without any effect
  are necessary to enable a rewrite that significantly improves accuracy.
Sometimes, even after the correct rewrite is found,
  terms need to be canceled before accuracy is gained.
Brute force search struggles with these cases.
To improve accuracy, important subexpressions
  must be found and focused on;
  sequences of rewrites need to be considered as a unit;
  and cancellation needs to occur automatically.

\casio's core is a simple loop
  which threads together several rewrite techniques,
  addressing each of these problems.
The loop tracks a set of candidate programs,
  each real-equivalent to the input.
Only programs which have the best-known accuracy
  on at least one input point are tracked.
In each iteration, \casio generates new candidates
  by choosing one alternative that has not been chosen before;
  finding expressions where a rewrite may lead to improvement;
  selecting the rewrite-rules which match the error-causing operator
  and applying a sequence of rewrites to enable the application of that rule;
  and simplifying the result, canceling like terms.
Then the best candidate is chosen for the next iteration.
Before entering the main loop,
  \casio analyzes the program for periodic subexpressions
  and attempts to optimize them separately.
After the main loop completes,
  \casio aggregates all candidates generated
  throughout the course of the loop,
  and infers regimes of input values for which
  to execute different candidates.

\begin{figure}
\begin{footnotesize}
\begin{align*}
  &\!def!\:\|casio|(e) \ceq \\
  &\> pts, exs \ceq \|pickPoints|(e) \\
  &\> e' \ceq \|simplify|(e) \\
  &\> t \ceq \|makeTable|(e'') \\
  &\> \|while|(\|not| \; t.\|done|) \\
  &\> \> e, t' \ceq \|pick|\;t \\
  &\> \> es \ceq \|map|\:\|simplify|\:(\|map|\:\|rr|\:(\|focus|\;e)) \\
  &\> \> t \ceq t' \cup es \\
  &\> \!return!\:\|regimes|\:(\cup\{\|correlate|\;e \I e \in t \})
\end{align*}
\end{footnotesize}
\caption{The \casio main loop.
  \casio initializes its sample points, exact outputs,
    and candidate program table $t$, and enters the main loop.
  At each step through the loop, a candidate $e$ is chosen from $t$,
    and explored by focusing on expressions with local errors,
    rewriting those expressions, and simplifying the results.
  When all candidates have been explored,
    regime inference is used to combine the found candidates.
  Extra candidates are generated at the end by attempting to correlated error.}
\label{alg:main}
\end{figure}

\subsection{Sampling points}

\casio uses sampled input points to guide its search.
\nSample input points are used
  for estimating the error of candidate programs;
  as discussed in Section~\ref{sec:eval-eval},
  this is sufficient for accurately evaluating the accuracy
  of candidate programs.
These input points are sampled uniformly
  from the set of floating point \emph{values}.
That is, each sampled point is a combination of a random
  mantissa, exponent, and sign bit.

This unusual distribution of samples serves two purposes.
First, by sampling exponents uniformly, \casio generates
  both very small and very large input points.
A sampling strategy that simply samples uniformly between
  the maximum and minimum finite floating point values
  would almost never sample values very close to zero,
  and would thus be unlikely to mitigate rounding error for small values.
If \casio is run with this strawman sampling strategy,
  it is unable to solve any but the most trivial examples.
Second, the uniform sampling over exponents allows
  accurately evaluating the correct output for each input point.

\casio must produce a program which approximates
  the ideal, real-number semantics of the original program.
This requires knowing the output generated by
  the real-number semantics of the original program
  on the sampled input points.
However, the real-number semantics is not executable,
  since exact real numbers cannot be efficiently represented on a computer.
Instead, \casio uses arbitrary precision floating point
  as provided by GNU~MPFR~\cite{acm07-mpfr}.
Arbitrary precision floating point requires selecting a precision in bits,
  which MPFR will simulate in software.

\casio must choose a sufficiently high level of precision,
  lest the ground truth against which it evaluates candidate programs is incorrect.
However, accuracy does not improve smoothly with precision.
Consider the program $((1 + x^k) - 1) / x^k$ at $x = \frac12$.
Until $k$ bits of precision are available,
  the computed answer is $0$, even though the correct result is $1$.
Once $k$ bits are available, the correct answer is computed exactly.
A similar pattern occurs with many real-world programs.
To mitigate it, we increase working precision
  until further increases in precision do not change
  the computed answer for any input point, to 64 bits.
We have found this method to select a sufficiently large
  working precision for arbitrary precision evaluation;
  the precision required can be as large as 560 bits
  (see Figure~\ref{fig:eval-mpfr-bits} in Section~\ref{sec:evaluation}).
We have found all candidate programs evaluate
  to the same values in arbitrary precision,
  suggesting that further increases in working precision are unnecessary.

Once sample points are chosen and exact and floating-point answers
  are computed, some measure of error is necessary to compare the two.
Mathematically-natural measures include absolute and relative error.
However, both of these measures are ill-suited to measuring error
  between floating-point values~\cite{pldi14-stoke}.
We follow \textsc{Stoke}~\cite{pldi14-stoke}
  in defining the error between $x$ and $y$ by
  the number of floating-point values in the range $[x, y]$:
\[
\!def!\:\Err(x, y) \ceq \#\{ z : \FP_{64}\:|\:x \le z \le y \}
\]
This measure of error is uniform over the input space
  and avoids special handling for infinite and denormal values.

\subsection{Focusing with local error}

If \casio detects that the input program
  has significant floating-point error,
  \casio applies errors to reduce it.
For large programs, many rewrites are possible;
  to reduce this search space,
  \casio must identify which expressions are the source of rounding error.
The error in computing each subexpression
  is a rough measure for which expressions are the source of error;
  however, it this measure is biased toward larger expressions,
  because functions whose arguments are computed high error
  usually compute results with high error%
  \footnote{Garbage in, garbage out}.
\casio eliminates this bias by focusing on expressions
  with high \emph{local error}.
The local error of an expression
  is the error in its output if it were called with exactly-computed inputs:
\begin{align*}
  &\!def!\:\|localerror|(ctx, f(e_1, \dotsc, e_k)) \ceq \\
  &\> e_i' \ceq \|eval|_\infty(ctx, e_i) \\
  &\> r_{64} \ceq f_{64}(\F_{64}(e_1'), \dotsc, \F_{64}(e_k')) \\
  &\> r_\infty \ceq \F_{64}(f_\infty(e_1', \dotsc, e_k')) \\
  &\> \!return!\:\Err(r_{64}, r_\infty)
\end{align*}
By exactly evaluating inputs,
  \casio avoids penalizing the output of operators
  for errors in computing their inputs.
Figure~\ref{alg:focus} gives pseudo-code for computing local error.
\casio computes the local error of each sub-expression at every sample point,
  and selects the three expressions with the highest local error
  for rewriting.

\subsection{Recursive rewrite pattern matching}

After focusing on an expression using local error,
  \casio must apply rewrite rules to that expression.
A common problem is that an expression may require multiple rewrites
  to enable a rewrite that actually improves accuracy.
For example, consider the expression
\[
 \left(\frac{1}{x-1} - \frac{2}{x} \right) + \frac{1}{x+1}.
\]
\casio correctly identifies the $(+)$ operator
  to have the most local error
  (it adds terms with similar values and opposite signs).
To improve the accuracy of this program,
  all of the fractions must be placed under a common denominator,
  and then the numerator must be simplified.
\casio has rules for fraction addition and subtraction;
  however, doing a single fraction addition or subtraction
  does not significantly change the accuracy of the program,
  since accuracy loss is caused by a cancellation
  that occurs when \emph{all} values are added together.
In order to improve the accuracy of this program,
  \casio must use the fraction addition/subtraction rules twice:
  once on the parenthesized subtraction,
  then again for the remaining addition.
The first rewrite must occur not at the focused-upon expression,
  but on a child expression;
  this rewrite is necessary for enabling a later rewrite
  at the focused-upon expression.

\casio automatically finds sequences of rewrites like this example,
  where subexpressions are rewritten
  to allow a rewrite of the parent expression.
In order to rewrite an expression to match a rule,
  \casio rewrites each subexpression, recursively,
  to match its associated pattern in the rule
  (if the subexpression already matches, the recursion terminates).
This recursive algorithm produces dozens of rewrite sequences
  for each focused location; they vary from one to eight sequences in length.

\subsection{Simplification}

In order to improve the accuracy of a formula,
  it is often necessary to first apply a rewrite rule
  at an expression of high error,
  and then cancel like terms and function inverses.
For example, \casio will rewrite $\sqrt{x+1} - \sqrt{x}$,
  into $(\sqrt{x+1}^2 - \sqrt{x}^2) / (\sqrt{x+1} + \sqrt{x})$.
On it's own, this transformation does not reduce error.
However, the numerator of this fraction simplifies to just $1$,
  and $1/(\sqrt{x+1} + \sqrt{x})$ is a much more accurate program
  than the original $\sqrt{x+1} - \sqrt{x}$.
To find such beneficial transformations,
  \casio automatically simplifies the expressions generated by the recursive matcher.
This simplification pass automatically
  removes function inverses (as in $\sqrt{x}^2$),
  cancels like terms (as in $x - x$),
  and combines terms (as in $x + x$).
It is implemented as a tree walk over programs,
  which first removes function inverses,
  then reduces each expression into a polynomial canonical form,
  and cancels like terms.
Such transformations are difficult to find heuristically, 
  as they involve long chains of reassociation and commutation rewrites.
A separate simplification pass allows these transformations
  to be discovered easily.

\subsection{Regime inference}

Often two real-equivalent programs have incomparable accuracy---%
  one performs better on some inputs, but worse on others.
The quadratic formula, discussed in Section~\ref{sec:overview},
  is striking example of this phenomenon.
To accurately evaluate the quadratic formula,
  both expressions
\begin{align*}
  \frac{-b + \sqrt{b^2 - 4 a c}}{2 a} &&
  \frac{2 c}{-b - \sqrt{b^2 - 4 a c}}
\end{align*}
  are necessary,
  the first for $b < 0$ and the second for $b \ge 0$.
A similar pattern occurs in many real-world programs,
  with different programs being most accurate
  for different input regions.
The process that automatically detects
  that two programs are best on different inputs,
  and automatically infer the regimes
  is called \emph{regime inference}.

\casio's regime inference must balances
  the cost of adding a branch against the potential benefit of doing so:
  branches are computationally expensive.
\casio must also avoid overfitting the sampled points;
  very small regimes likely represent
  some peculiar behavior of the sampled points.
To avoid overfitting and generating slow programs,
  \casio observes two constraints on the regimes it infers:
  it infers no more than \nRegimes per input variable;
  and, it infers the existence of a regime
  only if it improves average accuracy by at least one bit.

The simplest way to infer regimes would be to try
  to place a regime boundary between every set
  of \nRegimes pairs of consecutive sample points.
Unfortunately, with \nSample sample points,
  this brute-force approach would be incredibly expensive
  (there are nine trillion such sets of five pairs).
Instead, \casio uses dynamic programming
  to find the optimal set of up to five consecutive sample points.
The dynamic program computes the optimal set
  of at most $k$ regimes in $(-\infty, x_i)$, where $x_i$ is a sampled point;
  this problem has the optimal substructure property
  required for dynamic programming.
Figure~\ref{fig:regimes} contains the algorithm in detail.
This algorithm is quadratic in the number of sample points,
  and linear in the number of regimes;
  we have found this algorithm to be sufficiently fast for \casio.
Once \casio has determined that branch should be placed
  between two sampled points,
  it uses a binary search on the chosen variable to 
  find the exact value location of the regime boundary.

\begin{figure}
\begin{footnotesize}
\begin{align*}
  &\!def!\:\|regimes|(\{p_1, \dotsc, p_c\}) \ceq \\
  &\> N \ceq \text{Sampled points} \\
  &\> r_{t,0} \ceq p_{i_1}, \text{ where } p_{i_1} \text{ best on } [0, x_t] \\
  &\> \varepsilon_{t,0} \ceq \|avgerror|(r_{t,0}, [0, t]) \\
  &\> \!for!\:k \in \{1, \dotsc, \nRegimes \} \\
  &\> \> r_{t,k} \ceq \min_s \{ (r_{s,k}, p_k) | \\
  &\> \> \> p_k \text{ best on } [x_s, x_t], \\
  &\> \> \> r_{s,k} = [r_{s',k-1}, p_{k-1}], \\
  &\> \> \> \left(\sum_{i = s}^t \|error|(p_k, i)\right) >
  N + \left(\sum_{i = s}^t \|error|(p_{k - 1}, i)\right) \} \\
  &\> r_{t,\star} \{ (r_{t,\nRegimes}, p_k) | p_k \text{ best on } [x_t, \infty] \} \\
  &\> \!return!\:r_{t,\star}, \text{ for } r_{t, \star} \text{ best of all } t
\end{align*}
\end{footnotesize}
\caption{A dynamic programming algorithm for regime inference.
  For $k \in \{0,\dotsc,\nRegimes\}$ and $t \in \{1, \dotsc, N\}$,
    the best way to split $(-\infty, x_t]$ into up to $k$ regimes is computed
    by considering, for all $s$,
    the best way of splitting $(-\infty, x_s]$ into regimes
    along with the best program on $[x_s, x_t]$.
  The best way of splitting $(-\infty, \infty)$ into regimes
    is the best way, over all $t$, of splitting $(-\infty, x_t)$ into regimes
    plus the best possible program on $(x_t, \infty)$.
  After the regimes are found,
    each boundary is improved by a binary-search
    between the two sampled points that it lies between.}
\label{alg:main}
\end{figure}

\subsection{Candidate programs table}

Between iterations of the core loop,
  \casio stores only those candidate programs
  which are more accurate (of all generated candidates)
  on at least one sample point.
This allows programs that are accurate
  on only some input values to be explored
  without having to explore exponentially-many candidates.
When new candidate programs are generated,
  this set must be updated.

To update this set efficiently, \casio stores two maps:
  a map from points to a set of alternatives that do best at that point,
  and a map from alternatives to the points they do best at.
A candidate is added to this data structure
  only if it is better at some point
  than the alternatives currently stored for that point.
The alternatives that are no longer best at this point
  are removed from the data structure
  if there are no more points that they are best at.
This ensures that a minimal number of alternatives are stored.
This update rule is also biased toward keeping alternatives
  that were already contained in the table:
  this minimizes the amount of work that \casio does.

\subsection{Correlating Error}

In rewriting expressions where local error is high,
  \casio is using the assumption
  that the accuracy of a program can only be improved
  by improving the accuracy of each expression in it.
This assumption is often true in practice;
  however, it is sometimes best not to reduce the error in a subexpression,
  but instead to introduce error into a different expression,
  so that the errors cancel.
A simple example of this approach,
  presented by William Kahan~\cite{kahan-java-hurts},
  is the formula $(e^x - 1) / x$.
This formula is inaccurate for $x$ near $0$,
  because of rounding error when computing $e^x$.
However, if the denominator is changed from $x$ into $\log e^x$,
  the same rounding occurs in the denominator;
  when the two values are divided, the answer is $1$, which is correct.

\casio use this trick.
After the main rewrite loop is complete,
  \casio finds all remaining expressions with error,
  and tries rewrite any siblings of those expressions or their ancestors.
This produces many candidates, but since it is done only once
  and after the main rewrite loop is complete, the associated cost is small.
We've found this technique to be useful in only a small number of cases,
  but in those cases it is the necessary for reducing error.

\end{document}
