\documentclass[paper.tex]{subfiles}
\begin{document}

\section{Introduction}
\label{sec:intro}

From physical control systems to financial forecasting, many
applications are designed to compute over real numbers.  However,
practical concerns such as timeliness and space efficiency typically
force these applications to approximate their results using
hardware-supported floating point operations.  Unfortunately, the
finite precision offered by floating point computations leads to
rounding error; for many computations even miniscule errors can
propagate to produce completely incorrect results.

\fun{In response to the ubiquity and diabolical subtlety of floating
  point computation,} the numerical methods community provides a host
of powerful techniques to analyze and mitigate such numerical
inaccuracies.  These approaches rely on a deep understanding of the
floating point representation, sophisticated error analyses, and
optimizations to avoid expensive operations where high accuracy is
unnecessary or to improve accuracy where it is
essential. Unfortunately, while most programmers are instilled with a
sort of superstitious unease about the use of floating point, very few
possess the background required to manually employ numerical methods
techniqes.

Fortunately, simplified versions of many numerical methods techniques
are being automated, thus making the hard won knowledge of that
community more generally accessible to non-experts and providing tools
to make even experts more effective.

In practice, programmers often attempt to avoid numerical inaccuracy
by simply increasing precision, for example by replacing 32-bit floats
with 64-bit floats.  However, choosing the right representation is
hard.  Speed and space and precision tradeoffs.  Choosing right
tradeoff requires error analysis.  Several techniques exist to
automatically analyze floating point precision errors CITE CITE CITE
and help the developer choose an appropriate precision CITE CITE CITE
\todo{Precimonious.  Lam from UMD.  lots of other automated error
  analysis}.  Note that, even when applications can afford to simulate
arbitrary precision floats in software, these challenges still arise.


Hardware-supported floating point representations come in coarse,
exponentially growing sizes.  Recent work from the approximate
computing community helps avoid paying speed and energy overheads for
precision the developer may not need. \todo{STOKE. Luis. Martin.}  New
verification techniques help the programmer ensure they have all the
bits they think they need \todo{eva}.  Testing for overflow,
underflow, error \todo{popl13}.

However, to the best of our knowledge, one traditional task of the
numerical methods expert remains manual: rewriting the floating
program to \textit{improve} precision.  This has many benefits.

We do a clever search.

Contributions.

Outline.

----

Approximating real computations with floating point is one of the oldest
forms of approximate computing.  Unfortunately, providing good
approximations is often incredibly difficult due to the subtleties of how
rounding error can propagate through a computation.  The problem is that we
are victims of our success: in practice floating point often works quite
well, to the degree that most programmers simply think of floating point
computation as real computation.  Unfortunately, when those computations go
wrong, they can go horribly, horribly wrong.  Figuring out why requires
deep understanding of floating point, which is rare and expensive.

Floating point computation is a well known approach to approximating real
computation in the bounded context of practical hardware.  Recent advances
provide techniques to trade-off accuracy for improved speed and power usage
at the cost of precision.  However, this work is often carried out under
the assumption that the original floating program is the ``ground truth'',
that is, that it is already an acceptable approximation of the original
real computation the programmer had in mind.  Unfortunately, approximating
real computation in floating point presents many subtle challenges which,
if not accounted for, can yield arbitrarily large errors.  This limits the
value of recent advances improving the runtime and power efficiency of such
computations: the wrong answer is simply arrived at more quickly using
fewer joules (watts? ugh).

The field of numerical methods provides a rich set of techniques for
improving the numerical accuracy and precision of real computations
approximated in floating point.  Unfortunately, applying these techniques
has traditionally demanded extensive training and expensive manual analysis
and optimization of numerical programs.  As more and more scientists write
numerical programs, this lack of accuracy becomes increasingly troubling.
These non-expert programmers usually lack the training and time necessary
to employ numerical methods in their code, and often may not even be aware
of the subtle challenges this domain presents.

We present a new tool, \casio, which synthesizes floating point programs
which better approximate the real computations programmers have in mind.
Casio works by performing a heuristic search over the space of programs
equivalent to the input program over the reals.  Each step of the search
attempts to apply identity transformations over the reals that have been
shown valuable in the numerical methods literature.  Casio also searches
for alternate representations of programs that may be challenging for even
for numerical methods experts to develop, for example, special casing
variants of the program to input domains with better precision for that
variant.

We evaluate \casio on a number of examples drawn from numerical methods
textbooks, scientific journal articles, and math libraries.  We find that
\casio is often able to improve the precision of these examples
considerably.

\end{abstract}

\end{document}

\end{document}
