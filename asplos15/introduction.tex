\documentclass[paper.tex]{subfiles}
\begin{document}

\section{Introduction}
\label{sec:intro}

From physical control systems to financial forecasting, many
applications are designed to compute over real numbers.  However,
practical concerns such as latency and memory usage typically force
these applications to approximate their results using
hardware-supported floating point operations.  Unfortunately, the
finite precision offered by floating point computations can lead to
rounding error; for many computations even miniscule errors can
propagate to produce completely incorrect results.

In response to the ubiquity and subtlety of floating point
computation, the numerical methods community has developed a host of
powerful techniques to analyze and mitigate numerical inaccuracies.
These approaches rely on a deep understanding of the floating point
representation, sophisticated error analyses to choose an appropriate
precision, and optimizations to improve accuracy when additional
precision is unavailable or too expensive in terms of space or time.
Unfortunately, while most programmers are instilled with a sort of
superstitious unease concerning floating point, very few possess the
background required to manually apply traditional numerical methods
techniques. \todo{prev sentence bad flow, but so funny}

To ease the programmer's burden, researchers have begun automating
some of the important tasks for ensuring numerical accuracy.  The
resulting tools not only make the hard won knowledge of the numerical
methods community more generally accessible to non-experts, but also
help make experts more effective.  In particular, researchers have
developed techniques to automatically measure error, automatically
choose between available hardware-supported precisions, and optimize
computations to avoid expensive operations for precision that is not
required.

In practice, programmers often attempt to avoid numerical inaccuracy
by simply increasing precision, for example by replacing 32-bit floats
with 64-bit floats.  However, choosing the right representation is
hard.  Speed and space and precision tradeoffs.  Choosing right
tradeoff requires error analysis.  Several techniques exist to
automatically analyze floating point precision errors CITE CITE CITE
and help the developer choose an appropriate precision CITE CITE CITE
\todo{Precimonious.  Lam from UMD.  lots of other automated error
  analysis}.  Note that, even when applications can afford to simulate
arbitrary precision floats in software, these challenges still arise.

Hardware-supported floating point representations come in coarse,
exponentially growing sizes.  Recent work from the approximate
computing community helps avoid paying speed and energy overheads for
precision the developer may not need. \todo{STOKE. Luis. Martin.}  New
verification techniques help the programmer ensure they have all the
bits they think they need \todo{eva}.  Testing for overflow,
underflow, error \todo{popl13}.

However, to the best of our knowledge, one traditional task of the
numerical methods expert remains manual: rewriting the floating
program to \textit{improve} precision.  This has many benefits.

Our insight is to search for programs which are equivalent over the
reals but induce lower error over floats.  We use a database of common
mathematical identities and apply in a hill climbing search.  It's
stupid, but it works super well.

We evaluate on a bunch of stuff.

Good anecdote about Harley.

In summary, this paper makes three primary contributions:
\begin{enumerate}
\item contribution 1
\item contribution 2
\item contribution 3
\end{enumerate}

The rest of the paper is organized as follows: OUTLINE

----

Approximating real computations with floating point is one of the oldest
forms of approximate computing.  Unfortunately, providing good
approximations is often incredibly difficult due to the subtleties of how
rounding error can propagate through a computation.  The problem is that we
are victims of our success: in practice floating point often works quite
well, to the degree that most programmers simply think of floating point
computation as real computation.  Unfortunately, when those computations go
wrong, they can go horribly, horribly wrong.  Figuring out why requires
deep understanding of floating point, which is rare and expensive.

Floating point computation is a well known approach to approximating real
computation in the bounded context of practical hardware.  Recent advances
provide techniques to trade-off accuracy for improved speed and power usage
at the cost of precision.  However, this work is often carried out under
the assumption that the original floating program is the ``ground truth'',
that is, that it is already an acceptable approximation of the original
real computation the programmer had in mind.  Unfortunately, approximating
real computation in floating point presents many subtle challenges which,
if not accounted for, can yield arbitrarily large errors.  This limits the
value of recent advances improving the runtime and power efficiency of such
computations: the wrong answer is simply arrived at more quickly using
fewer joules (watts? ugh).

The field of numerical methods provides a rich set of techniques for
improving the numerical accuracy and precision of real computations
approximated in floating point.  Unfortunately, applying these techniques
has traditionally demanded extensive training and expensive manual analysis
and optimization of numerical programs.  As more and more scientists write
numerical programs, this lack of accuracy becomes increasingly troubling.
These non-expert programmers usually lack the training and time necessary
to employ numerical methods in their code, and often may not even be aware
of the subtle challenges this domain presents.

We present a new tool, \casio, which synthesizes floating point programs
which better approximate the real computations programmers have in mind.
Casio works by performing a heuristic search over the space of programs
equivalent to the input program over the reals.  Each step of the search
attempts to apply identity transformations over the reals that have been
shown valuable in the numerical methods literature.  Casio also searches
for alternate representations of programs that may be challenging for even
for numerical methods experts to develop, for example, special casing
variants of the program to input domains with better precision for that
variant.

We evaluate \casio on a number of examples drawn from numerical methods
textbooks, scientific journal articles, and math libraries.  We find that
\casio is often able to improve the precision of these examples
considerably.

\end{document}
