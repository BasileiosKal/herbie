\documentclass[paper.tex]{subfiles}
\begin{document}

\section{Introduction}
\label{sec:introduction}

Many applications that depend on floating point arithmetic must
produce accurate results, from custom fluid dynamics simulators to
statistical analysis packages used across the sciences.  These
applications typically rely on hardware implementations of floating
point to efficiently approximate computations over real numbers.
Unfortunately, such approximations introduce rounding error which can
lead to unacceptably \textit{inaccurate} output, where floating point
results differ substantially from their ideal real number results.

% The efficiency provided by hardware implemented floating point
% enables these applications to effectively process large datasets.

Floating point inaccuracy is notoriously difficult to detect and debug
\todo{cite kahan}.  Rounding errors have lead to the retraction of
numerous scientific articles \todo{cite}, legal regulations in finance
\todo{cite}, distorted stock market indices \todo{cite}, and skewed
election results \todo{cite}.

In practice, developers often respond to rounding error by increasing
\textit{precision}, the size of the floating point representation.
For example, a developer might try to shift error to lower order bits
by replacing all 32-bit floats with 64-bit floats.  Unfortunately,
even the largest hardware-supported precision may still exhibit
unacceptable rounding error, and further increases to precision
require simulating arbitrary precision floating point in software,
incurring orders of magnitude slowdown\footnote{Even arbitrary
  precision software floating point can exhibit rounding error, and so
  the developer must still carefully select a precision that provides
  sufficient accuracy.}.

\todo{Pavel here} The numerical methods literature provides numerous
techniques to analyze and mitigate rounding error without increasing
precision. \todo{matrices, loops, stability, interpolation} In
particular, forward and backward error analysis \todo{cite} coupled
with various program transformations \todo{cite} can be applied to
improve accuracy without increasing precision.  Unfortunately,
applying these techniques often requires deep expertise and
substantial manual effort.

In response to these challenges, we introduce \casio, a first step
toward automatically improving floating point accuracy.  \casio
searches for error-reducing program transformations by combining three
novel techniques.  First, \casio estimates which operations are
responsible for rounding error by carefully sampling floating point
inputs and comparing the results of intermediate operations against
accurate results computed in arbitrary precision software floating
point.  Second, based on the error's characteristics, \casio selects
various program transformations from a database, applies them
independently, and measures their impact on accuracy.  Third, because
transformations may not uniformly improve accuracy across the floating
point domain, \casio detects input regimes where error behavior
changes and combines multiple program variants to reduce overall
error.  By combining these techniques, \casio reduces rounding error
automatically, requiring no training or manual intervention from the
programmer.

We evaluate \casio on benchmarks drawn from numerical methods
textbooks and consider its broader applicability to a mathematical
library as well as formulas drawn from recent scientific articles.
Our results demonstrate that \casio can effectively discover
transformations that substantially reduce error while imposing modest
overhead.  By searching through thousands of candidate programs, our
prototype implementation is able to \todo{impressive summary of
  evaluation}.  Furthermore, we evaluate our technique on
\todo{microbenchmarks and application} and demonstrate that we can
substantially improve accuracy while imposing only modest overhead.
Furthermore, \casio has already been found useful by colleagues in
machine learning who were able to significantly reduce the rounding
error of their learning algorithm.

In summary, this paper presents \casio, an \textit{automated}
technique to improve floating point accuracy by searching for program
transformations inspired by the numerical methods literature.  \casio
contributes three novel techniques:
\begin{enumerate}
\item A goal directed search for improving floating point accuracy,
  guided by techniques that estimate rounding error and its causes
\item A technique that iteratively applies local, domain specific
  rewrites, causing traditional error-reducing program transformations
  to fall our naturally
\item Approaches to both detecting regimes where error behavior
  changes and also combining multiple program versions to reduce
  overall error
\end{enumerate}
Furthermore, the \casio infrastructure provides a foundation for
others to build upon and explore issues around numerical computing
such as additional techniques to mitigate rounding error, improving
stability, matrices, loops, programmer interfaces.

The rest of the paper is organized as follows.  \Cref{sec:background}
provides a brief background on floating point arithmetic.
\Cref{sec:overview} illustrates \casio on a representative example and
describes the high level \casio workflow.  \Cref{sec:synthesis}
details \casio's heuristic search and error estimation techniques.
\Cref{sec:evaluation} evaluates \casio's effectiveness across a suite
of microbenchmarks, two large applications, and the effort to build
and run \casio.  \Cref{sec:relatedwork} surveys the most closely
related work and \Cref{sec:futurework} considers future work and
concludes.


% GRAVEYARD

% Unfortunately, while most programmers are instilled with a sort of
% superstitious unease concerning floating point, very few possess the
% background required to manually apply the traditional numerical
% methods techniques that address these challenges.

% Many developers are instilled with a sort of superstitious unease
% concerning floating point.

% not only make the hard won knowledge of the numerical methods
% community more generally accessible to non-experts, but also help
% make experts more effective

% \casio complements several recent efforts to improve overall floating
% point computation.  Our technique is parameterized by error estimation
% so we can adopt state of the art techniques as they are developed.
% STOKE can work as a post processing pass.

% In particular, researchers have developed techniques to
% automatically measure error, automatically choose between available
% hardware-supported precisions, and optimize computations to avoid
% expensive operations for precision that is not required.

% However, this work is often carried out under the assumption that
% the original floating program is the ``ground truth'', that is, that
% it is already an acceptable approximation of the original real
% computation the programmer had in mind.  Unfortunately,
% approximating real computation in floating point presents many
% subtle challenges which, if not accounted for, can yield arbitrarily
% large errors.  This limits the value of recent advances improving
% the runtime and power efficiency of such computations: the wrong
% answer is simply arrived at more quickly using fewer joules (watts?
% ugh).

% Casio works by performing a heuristic search over the space of
% programs equivalent to the input program over the reals.  Each step
% of the search attempts to apply identity transformations over the
% reals that have been shown valuable in the numerical methods
% literature.  Casio also searches for alternate representations of
% programs that may be challenging for even for numerical methods
% experts to develop, for example, special casing variants of the
% program to input domains with better precision for that variant.

\end{document}