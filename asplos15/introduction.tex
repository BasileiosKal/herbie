\documentclass[paper.tex]{subfiles}
\begin{document}

\section{Introduction}
\label{sec:introduction}

\note{jrw moved this paragraph up!}
Floating point inaccuracy is notoriously difficult to detect and
debug~\cite{berkeley00-needle-like, kahan-java-hurts}.  Rounding
errors have lead to irreproducibility and even retraction of
scientific articles~\cite{num-issues-in-stat, num-replication,
  stat-robustness}, legal regulations in finance~\cite{euro-rounding},
distorted stock market indices~\cite{distort-stock,
  wall-street-distort-stock}, and skewed election
results~\cite{round-elections}.
Many applications\jdiff{}{, from physical simulators to statistical
  packages,} \jdiff{that}{} depend on floating point arithmetic
\jdiff{must}{to} produce accurate results\jdiff{, including fluid
  dynamics simulators and statistical packages used across the
  sciences}{}.  These applications typically \jdiff{rely on}{use}
floating point hardware to efficiently approximate computations over
real numbers.  \jdiff{Unfortunately, such approximations}{While such
  approximations make these computations feasible, they also}
introduce rounding error\jdiff{}{,} which can lead to unacceptable
\textit{accuracy}, \jdiff{where floating point and ideal real number
  results differ substantially}{that is, the approximate results may
  differ from the ideal real number results by an unacceptable
  margin}.

% The efficiency provided by hardware implemented floating point
% enables these applications to effectively process large datasets.

In practice, developers often respond to rounding error by increasing
\textit{precision}, the size of the floating point representation.
For example, a developer might try to shift error to lower order bits
by replacing all 32-bit~floats with 64-bit~floats\jdiff{}{ that is,
  double precision floats}.  Unfortunately, even the largest
hardware-supported precision may still exhibit unacceptable rounding
error, and further increases to precision require simulating arbitrary
precision floating point in software, incurring orders of magnitude
slowdown\footnote{Even arbitrary precision floating point can exhibit
  rounding error, and so the developer must still carefully select a
  precision that provides sufficient accuracy.}.

The numerical methods literature provides techniques to analyze and
mitigate rounding error without increasing precision.  Forward and
backward error analysis \todo{cite} can be applied to measure the
error of a program, and various program transformations \todo{cite}
can be applied to improve accuracy.  Numerical methods is a vast
field, which can also support programmers in the accuracy of matrix
computations, avoid accumulating error in a loop, and replacing
unstable algorithms with numerically stable ones.  Unfortunately,
these techniques often require both understanding the subtle details
of floating point arithmetic and also manually rearranging
computations.

As a first step toward addressing these challenges, we introduce
\casio, a technique for automatically mitigating rounding error in
floating point computations.  \casio searches for error-reducing
program transformations by combining three novel techniques.  First,
\casio \jdiff{estimates}{determines} which operations are responsible
for rounding error by sampling floating point inputs and comparing the
results of intermediate operations against accurate results computed
using arbitrary precision floating point.  Second, \casio applies
\jdiff{various rewrites based on the error's source, measures their
  individual effects on accuracy, and chooses a subset of program
  variants to continue improving}{a database of rewrite rules to the
  error's source to produce program variants that are evaluated to
  determine which variants have higher accuracy than the original
  program}. Third, \casio detects \jdiff{input regimes where error
  behavior changes and combines multiple program variants to reduce
  overall error}{when two or more program variants have complementary
  error behavior on different parts of the input space and combines
  these programs to improve overall accuracy}.

\jdiff{By combining these techniques,}{Thus} \casio improves
accuracy automatically, without requiring the programmer to learn the
details of floating point arithmetic or manually rearrange
computations.

We evaluate \casio on examples drawn from a classic numerical methods
textbook and consider its broader applicability to floating point
expressions extracted from a mathematical library as well as formulas
from recent scientific articles.  Our results demonstrate that \casio
can effectively discover transformations that substantially improve
accuracy (\todo{quantitative result here}) while imposing much lower
overhead than software floating point (\todo{quantitative result
  here}).  Furthermore, \casio has already been applied by colleagues
in machine learning who were able to significantly reduce rounding
error that arose when computing probabilities in a clustering
algorithm.

\note{jrw thinks this summary section should be struck, but then the
  transition into the outline is awkward.} In summary, \casio
contributes three novel techniques to automatically improve floating
point accuracy:
\begin{enumerate}
\item A goal directed search for accuracy-improving program
  transformations, guided by techniques that estimate rounding error
  and its sources;
\item A technique that iteratively applies local, error-specific
  rewrites, causing traditional error-reducing program transformations
  to fall out naturally;
\item Approaches to both detecting regimes where error behavior
  changes and also combining multiple program variants to reduce
  overall error.
\end{enumerate}

The rest of the paper is organized as follows.  \Cref{sec:background}
provides a brief background on floating point arithmetic.
\Cref{sec:overview} illustrates \casio on a representative example and
describes the high level \casio workflow.  \Cref{sec:synthesis}
details \casio's heuristic search and error estimation techniques.
\Cref{sec:evaluation} evaluates \casio's effectiveness at improving
accuracy and measures \casio's performance overhead.
\Cref{sec:relatedwork} surveys the most closely related work while
\Cref{sec:futurework} considers future directions for \casio.


% GRAVEYARD

% Unfortunately, while most programmers are instilled with a sort of
% superstitious unease concerning floating point, very few possess the
% background required to manually apply the traditional numerical
% methods techniques that address these challenges.

% Many developers are instilled with a sort of superstitious unease
% concerning floating point.

% not only make the hard won knowledge of the numerical methods
% community more generally accessible to non-experts, but also help
% make experts more effective

% \casio complements several recent efforts to improve overall floating
% point computation.  Our technique is parameterized by error estimation
% so we can adopt state of the art techniques as they are developed.
% STOKE can work as a post processing pass.

% In particular, researchers have developed techniques to
% automatically measure error, automatically choose between available
% hardware-supported precisions, and optimize computations to avoid
% expensive operations for precision that is not required.

% However, this work is often carried out under the assumption that
% the original floating program is the ``ground truth'', that is, that
% it is already an acceptable approximation of the original real
% computation the programmer had in mind.  Unfortunately,
% approximating real computation in floating point presents many
% subtle challenges which, if not accounted for, can yield arbitrarily
% large errors.  This limits the value of recent advances improving
% the runtime and power efficiency of such computations: the wrong
% answer is simply arrived at more quickly using fewer joules (watts?
% ugh).

% Casio works by performing a heuristic search over the space of
% programs equivalent to the input program over the reals.  Each step
% of the search attempts to apply identity transformations over the
% reals that have been shown valuable in the numerical methods
% literature.  Casio also searches for alternate representations of
% programs that may be challenging for even for numerical methods
% experts to develop, for example, special casing variants of the
% program to input domains with better precision for that variant.

\end{document}
